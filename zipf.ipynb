{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zipf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/javiervz/zipf/blob/master/zipf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "k_FFUcAF53U9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**A decentralized route to the origins of scaling in human language**"
      ]
    },
    {
      "metadata": {
        "id": "gU_J7TyG6PSB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, we create a population "
      ]
    },
    {
      "metadata": {
        "id": "dae-aooi5uGy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "db5QZ_FR514F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# periodic grid graph of dim 2 and length L\n",
        "def grid(L):\n",
        "  G = nx.grid_graph([L,L])\n",
        "  return G"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sDBp6yHUB3-1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# matrix of ones and zeros (at random)\n",
        "def lexical_matrix(n):\n",
        "  M=np.array([0 if random.random()<0.5 else 1 for i in range(n**2)]).reshape(n,n)\n",
        "  return M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "obCJdNRz9APR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# a population is defined by a (i) grid; and (ii) a dict of numpy matrices (representing vocabularies)\n",
        "# L -> lenght of the grid \n",
        "# n -> number of words (rows of the lexical matrices)\n",
        "# n -> number of meanings (columns of lexical matrices) (that is, only squared matrices)\n",
        "def population(L,n):\n",
        "  # grid graph\n",
        "  G=grid(L)\n",
        "  nodes=G.nodes()\n",
        "  lexical_dict={node:lexical_matrix(n) for node in nodes}\n",
        "  return [G,lexical_dict]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DRZx1NZE-aWs",
        "colab_type": "code",
        "outputId": "be245d6f-f263-431b-f32d-f2c974fa6c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "cell_type": "code",
      "source": [
        "population(5,2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<networkx.classes.graph.Graph at 0x7fcbd9ad95c0>, {(0, 0): array([[1, 1],\n",
              "         [1, 1]]), (0, 1): array([[0, 0],\n",
              "         [1, 0]]), (0, 2): array([[1, 0],\n",
              "         [0, 0]]), (0, 3): array([[0, 1],\n",
              "         [0, 1]]), (0, 4): array([[1, 0],\n",
              "         [0, 1]]), (1, 0): array([[1, 1],\n",
              "         [0, 0]]), (1, 1): array([[1, 0],\n",
              "         [1, 1]]), (1, 2): array([[1, 0],\n",
              "         [1, 0]]), (1, 3): array([[0, 0],\n",
              "         [0, 1]]), (1, 4): array([[0, 0],\n",
              "         [0, 1]]), (2, 0): array([[0, 0],\n",
              "         [0, 1]]), (2, 1): array([[1, 0],\n",
              "         [1, 1]]), (2, 2): array([[0, 0],\n",
              "         [1, 0]]), (2, 3): array([[0, 0],\n",
              "         [0, 0]]), (2, 4): array([[1, 1],\n",
              "         [0, 0]]), (3, 0): array([[1, 0],\n",
              "         [1, 1]]), (3, 1): array([[0, 1],\n",
              "         [1, 1]]), (3, 2): array([[1, 1],\n",
              "         [0, 0]]), (3, 3): array([[0, 1],\n",
              "         [0, 0]]), (3, 4): array([[1, 0],\n",
              "         [1, 1]]), (4, 0): array([[0, 0],\n",
              "         [1, 0]]), (4, 1): array([[0, 0],\n",
              "         [0, 0]]), (4, 2): array([[1, 1],\n",
              "         [0, 0]]), (4, 3): array([[1, 1],\n",
              "         [1, 0]]), (4, 4): array([[1, 1],\n",
              "         [0, 1]])}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "8X7dysfdFSjd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Second, we define some functions on lexical interests"
      ]
    },
    {
      "metadata": {
        "id": "df_bvR90FZ_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this function allows us to consider the level of lexical compromise of agents\n",
        "# matrix -> lexical matrix of the speaker\n",
        "# meaning -> selected column\n",
        "# speaker_interest -> if 0 the speaker selects the most ambiguous word; else, the speaker selects the least ambiguous word\n",
        "def select_word(matrix,meaning,speaker_interest):\n",
        "  # sum of rows (number of meanings!)\n",
        "  sum_rows=matrix.sum(axis=1)\n",
        "  # select the words with the most ambiguity if speaker==0\n",
        "  if speaker_interest==0:\n",
        "    ambiguity=max(sum_rows)\n",
        "  else:\n",
        "    ambiguity=min(sum_rows)\n",
        "  # indices associated to ambiguity\n",
        "  indices_ambiguity=[index for index in range(len(sum_rows)) if sum_rows[index]==ambiguity]\n",
        "  # select only one word!\n",
        "  word=random.choice(indices_ambiguity)\n",
        "  return word\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lTxC-nWvR9k-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now, we define a simple speaker-hearer interaction\n",
        "# speaker, hearer -> agent's locations (nodes!)\n",
        "# lexical_dict -> dictionary of lexical metrices\n",
        "# speaker_interest -> if 0 the speaker selects the most ambiguous word; else, the speaker selects the least ambiguous word\n",
        "# meaning -> the topic of the conversation\n",
        "def interaction(speaker,hearer,lexical_dict,speaker_interest,meaning):\n",
        "  # is there some word for the meaning?\n",
        "  # speaker's lexical matrix\n",
        "  speaker_matrix=lexical_dict[speaker]\n",
        "  if sum(speaker_matrix[meaning,:])==0:\n",
        "    # add some word\n",
        "    speaker_matrix[random.choice(range(len(speaker_matrix)))][meaning]=1\n",
        "    # update speaker's lexical matrix\n",
        "    lexical_dict[speaker]=speaker_matrix\n",
        "  # lexical matrices\n",
        "  hearer_matrix=lexical_dict[hearer]\n",
        "  speaker_matrix=lexical_dict[speaker]\n",
        "  # the speaker selects one word according to its lexical compromise\n",
        "  word=select_word(lexical_dict[speaker],meaning,speaker_interest)\n",
        "  # now, simple naming game rules\n",
        "  # the hearer does not know the word (failure!)\n",
        "  if hearer_matrix[word][meaning]==0:\n",
        "    hearer_matrix[word][meaning]=1\n",
        "  lexical_dict[hearer]=hearer_matrix\n",
        "  # else (success!)\n",
        "  if hearer_matrix[word][meaning]==1:\n",
        "    n=len(speaker_matrix)\n",
        "    for i in range(n):\n",
        "      # all words are set to 0\n",
        "      hearer_matrix[i][meaning]=0\n",
        "      speaker_matrix[i][meaning]=0\n",
        "    # except one!\n",
        "    hearer_matrix[word][meaning]=1\n",
        "    speaker_matrix[word][meaning]=1\n",
        "  # update dict of lexical matrices\n",
        "  lexical_dict[hearer]=hearer_matrix\n",
        "  lexical_dict[speaker]=speaker_matrix\n",
        "  return lexical_dict\n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zmZwCyFv1OHt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Third, preparing the simulation"
      ]
    },
    {
      "metadata": {
        "id": "jbdG5y4GJ45E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# simulation of the agent-based model\n",
        "# time -> number of interactions\n",
        "# P -> population\n",
        "def simulation(time,P,speaker_interest,n):\n",
        "  # nodes \n",
        "  nodes=list(P[0].nodes())\n",
        "  # lexical_matrices\n",
        "  lexical_matrices=P[1]\n",
        "  # loop!\n",
        "  for i in range(time):\n",
        "    # topic of the conversation\n",
        "    meaning=random.choice(list(range(n)))\n",
        "    # speaker\n",
        "    speaker=random.choice(nodes)\n",
        "    # hearer\n",
        "    hearer=random.choice(list(P[0].neighbors(speaker)))\n",
        "    P[1]=interaction(speaker,hearer,P[1],speaker_interest,meaning)\n",
        "  \n",
        "  return P"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-XRAay1vpBxp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## measuring the effective vocabulary\n",
        "def effective_vocabulary(lexical_matrices,n): \n",
        "  a=0\n",
        "  for node in lexical_matrices.keys():\n",
        "    for i in range(n):\n",
        "      if sum(lexical_matrices[node][i,:])>0:\n",
        "        a+=1\n",
        "\n",
        "  return a/float(len(lexical_matrices.keys())*n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yUDBj-jbiP4_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d2c2b870-c303-4ef1-950c-805d24e32aa4"
      },
      "cell_type": "code",
      "source": [
        "P=population(32,3)\n",
        "print(effective_vocabulary(P[1],3))\n",
        "print(effective_vocabulary(simulation(100000,P,0,3)[1],2))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8792317708333334\n",
            "0.3134765625\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}