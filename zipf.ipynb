{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zipf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/javiervz/zipf/blob/master/zipf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "k_FFUcAF53U9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**A decentralized route to the origins of scaling in human language**"
      ]
    },
    {
      "metadata": {
        "id": "gU_J7TyG6PSB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, we create a population "
      ]
    },
    {
      "metadata": {
        "id": "dae-aooi5uGy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "db5QZ_FR514F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# periodic grid graph of dim 2 and length L\n",
        "def grid(L):\n",
        "  G = nx.grid_graph([L,L],periodic=True)\n",
        "  return G"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YE8XTWjO1igo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# complete graph of L**2 nodes\n",
        "def complete(L):\n",
        "  G = nx.complete_graph(L**2)\n",
        "  return G"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sDBp6yHUB3-1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# matrix of ones and zeros (at random)\n",
        "def lexical_matrix(n):\n",
        "  M=np.array([1 if random.random()<0.5 else 0 for i in range(n**2)]).reshape(n,n)\n",
        "  return M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "obCJdNRz9APR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# a population is defined by a (i) graph; and (ii) a dict of numpy matrices (representing vocabularies)\n",
        "# L -> length of the grid \n",
        "# n -> number of words (rows of the lexical matrices)\n",
        "# n -> number of meanings (columns of lexical matrices) (that is, only squared matrices)\n",
        "def population(L,n):\n",
        "  # grid (or complete) graph\n",
        "  G=grid(L)\n",
        "  nodes=G.nodes()\n",
        "  lexical_dict={node:lexical_matrix(n) for node in nodes}\n",
        "  return [G,lexical_dict]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8X7dysfdFSjd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Second, we define some functions on lexical interests"
      ]
    },
    {
      "metadata": {
        "id": "df_bvR90FZ_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this function allows us to consider the level of lexical compromise of agents\n",
        "# matrix -> lexical matrix of the speaker\n",
        "# meaning -> selected column\n",
        "# speaker_interest -> if 0 the speaker selects the most ambiguous word; else, the speaker selects the least ambiguous word\n",
        "def select_word(matrix,meaning,speaker_interest):\n",
        "  # if the speaker does not known any word associated to the meaning\n",
        "  if np.sum(matrix[:,meaning])==0:\n",
        "    word=random.randint(0,len(matrix[:,meaning])-1)\n",
        "  else:\n",
        "    # sum of rows (number of meanings!) associated to the meaning (using the hadamard product)\n",
        "    sum_rows=matrix.sum(axis=1)*matrix[:,meaning]\n",
        "    # select the words with the greatest ambiguity if speaker==0\n",
        "    if speaker_interest==0:\n",
        "      ambiguity=max(sum_rows)\n",
        "    else:\n",
        "      ambiguity=max(min(sum_rows),0)\n",
        "    # indices associated to ambiguity\n",
        "    indices_ambiguity=[index for index in range(len(sum_rows)) if sum_rows[index]==ambiguity]\n",
        "    # select only one word!\n",
        "    word=random.choice(indices_ambiguity)\n",
        "  return word\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lTxC-nWvR9k-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now, we propose a simple speaker-hearer interaction\n",
        "# speaker, hearer -> agent's locations (nodes!)\n",
        "# lexical_dict -> dictionary of lexical metrices\n",
        "# speaker_interest -> if 0 the speaker selects the most ambiguous word; else, the speaker selects the least ambiguous word\n",
        "# meaning -> the topic of the conversation\n",
        "def interaction(speaker,hearer,lexical_dict,speaker_interest,meaning):\n",
        "  # lexical matrices\n",
        "  hearer_matrix=lexical_dict[hearer]\n",
        "  speaker_matrix=lexical_dict[speaker]\n",
        "  # the speaker selects one word according to its lexical compromise\n",
        "  r=random.randint(0,100)\n",
        "  if float(r)/101>speaker_interest:\n",
        "    word=select_word(lexical_dict[speaker],meaning,0)\n",
        "  else:\n",
        "    word=select_word(lexical_dict[speaker],meaning,1)\n",
        "  # now, simple naming game rules\n",
        "  # the hearer does not know the word (failure!)\n",
        "  if hearer_matrix[word][meaning]==0:\n",
        "    hearer_matrix[word][meaning]=1\n",
        "  #lexical_dict[hearer]=hearer_matrix\n",
        "  # else (success!)\n",
        "  else:\n",
        "    n=len(speaker_matrix)\n",
        "    for i in range(n):\n",
        "      # all words are set to 0\n",
        "      hearer_matrix[i][meaning]=0\n",
        "      speaker_matrix[i][meaning]=0\n",
        "    # except one!\n",
        "    hearer_matrix[word][meaning]=1\n",
        "    speaker_matrix[word][meaning]=1\n",
        "  # update dict of lexical matrices\n",
        "  lexical_dict[hearer]=hearer_matrix\n",
        "  lexical_dict[speaker]=speaker_matrix\n",
        "  return lexical_dict\n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zmZwCyFv1OHt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Third, preparing the simulation"
      ]
    },
    {
      "metadata": {
        "id": "jbdG5y4GJ45E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# simulation of the agent-based model\n",
        "# time -> number of interactions\n",
        "# P -> population\n",
        "def simulation(time,P,speaker_interest,n):\n",
        "  # nodes \n",
        "  nodes=list(P[0].nodes())\n",
        "  # lexical_matrices\n",
        "  lexical_matrices=P[1]\n",
        "  # loop!\n",
        "  for i in tqdm(range(time)):\n",
        "    # topic of the conversation\n",
        "    meaning=random.randint(0,n-1)\n",
        "    # speaker\n",
        "    speaker=random.choice(nodes)\n",
        "    # hearer\n",
        "    hearer=random.choice(list(P[0].neighbors(speaker)))\n",
        "    P[1]=interaction(speaker,hearer,P[1],speaker_interest,meaning)\n",
        "  \n",
        "  return P"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-XRAay1vpBxp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## measuring the effective vocabulary\n",
        "def effective_vocabulary(lexical_matrices,n): \n",
        "  a=0\n",
        "  for node in lexical_matrices.keys():\n",
        "    for i in range(n):\n",
        "      if sum(lexical_matrices[node][i,:])>0:\n",
        "        a+=1\n",
        "\n",
        "  return a/float(len(lexical_matrices.keys())*n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rCrXDZ4preiN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n=64\n",
        "agents=64\n",
        "time=100000000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yUDBj-jbiP4_",
        "colab_type": "code",
        "outputId": "b04b90a2-b272-4422-e676-c297825f97ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "speaker_interest=0\n",
        "P=population(agents,n)\n",
        "print(effective_vocabulary(P[1],n))\n",
        "print(effective_vocabulary(simulation(time,P,speaker_interest,n)[1],n))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1388/100000000 [00:00<2:00:07, 13875.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 81%|████████  | 81110269/100000000 [1:58:27<27:52, 11294.83it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "e3PCdMcrzh8m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "speaker_interest=1\n",
        "P=population(agents,n)\n",
        "print(effective_vocabulary(P[1],n))\n",
        "print(effective_vocabulary(simulation(time,P,speaker_interest,n)[1],n))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m8Z05a-q7Hnu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "speaker_interest=[k/float(4) for k in range(5)]\n",
        "effective_vocabulary_dict={}\n",
        "for interest in speaker_interest:\n",
        "  P=population(agents,n)\n",
        "  effective_vocabulary_dict[interest]=effective_vocabulary(simulation(time,P,interest,n)[1],n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nKYJ9NL9Dzcn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "effective_vocabulary_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "itwNC6oReNj3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "initial_conditions=[(time,population(agents,64),k/float(4),64) for k in range(5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KYOGxynXepop",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2213
        },
        "outputId": "0e031464-0c0a-4314-9ccc-a02f5102232e"
      },
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "pool = Pool(processes=5)                                                        \n",
        "map_simulation=pool.starmap(simulation, initial_conditions)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 24413/100000000 [00:06<8:58:28, 3094.44it/s]Process ForkPoolWorker-663:\n",
            "Process ForkPoolWorker-666:\n",
            "Traceback (most recent call last):\n",
            "Process ForkPoolWorker-664:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
            "    return list(itertools.starmap(args[0], args[1]))\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"<ipython-input-8-ca2b87b67754>\", line 7, in simulation\n",
            "    for i in tqdm(range(time)):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 998, in __iter__\n",
            "    with self._lock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 106, in __enter__\n",
            "    self.acquire()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 99, in acquire\n",
            "    lock.acquire()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4da9b3cf61e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmap_simulation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_conditions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         '''\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
            "    return list(itertools.starmap(args[0], args[1]))\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"<ipython-input-8-ca2b87b67754>\", line 7, in simulation\n",
            "    for i in tqdm(range(time)):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
            "    return list(itertools.starmap(args[0], args[1]))\n",
            "  File \"<ipython-input-8-ca2b87b67754>\", line 7, in simulation\n",
            "    for i in tqdm(range(time)):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 998, in __iter__\n",
            "    with self._lock:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 1002, in __iter__\n",
            "    sp(self.__repr__())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 231, in print_status\n",
            "    fp_write('\\r' + s + (' ' * max(last_len[0] - len_s, 0)))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 225, in fp_write\n",
            "    fp_flush()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/iostream.py\", line 323, in flush\n",
            "    self._flush()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 106, in __enter__\n",
            "    self.acquire()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/iostream.py\", line 340, in _flush\n",
            "    parent=self.parent_header, ident=self.topic)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\", line 748, in send\n",
            "    stream.send_multipart(to_send, copy=copy)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/iostream.py\", line 199, in send_multipart\n",
            "    self.schedule(lambda : self._really_send(*args, **kwargs))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/iostream.py\", line 192, in schedule\n",
            "    f()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/iostream.py\", line 199, in <lambda>\n",
            "    self.schedule(lambda : self._really_send(*args, **kwargs))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 99, in acquire\n",
            "    lock.acquire()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/iostream.py\", line 215, in _really_send\n",
            "    ctx.term()\n",
            "  File \"zmq/backend/cython/context.pyx\", line 136, in zmq.backend.cython.context.Context.term\n",
            "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "  0%|          | 17447/100000000 [00:05<9:13:46, 3009.09it/s] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wJ4-SGPXq7Mn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(n,agents)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}