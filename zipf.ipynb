{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zipf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/javiervz/zipf/blob/master/zipf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "k_FFUcAF53U9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**A decentralized route to the origins of scaling in human language**"
      ]
    },
    {
      "metadata": {
        "id": "gU_J7TyG6PSB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, we create a population "
      ]
    },
    {
      "metadata": {
        "id": "dae-aooi5uGy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "db5QZ_FR514F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# periodic grid graph of dim 2 and length L\n",
        "def grid(L):\n",
        "  G = nx.grid_graph([L,L],periodic=True)\n",
        "  return G"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YE8XTWjO1igo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# periodic grid graph of dim 2 and length L\n",
        "def complete(L):\n",
        "  G = nx.complete_graph(L**2)\n",
        "  return G"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sDBp6yHUB3-1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# matrix of ones and zeros (at random)\n",
        "def lexical_matrix(n):\n",
        "  M=np.array([0 if random.random()<0.5 else 1 for i in range(n**2)]).reshape(n,n)\n",
        "  return M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "obCJdNRz9APR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# a population is defined by a (i) grid; and (ii) a dict of numpy matrices (representing vocabularies)\n",
        "# L -> lenght of the grid \n",
        "# n -> number of words (rows of the lexical matrices)\n",
        "# n -> number of meanings (columns of lexical matrices) (that is, only squared matrices)\n",
        "def population(L,n):\n",
        "  # grid graph\n",
        "  G=complete(L)\n",
        "  nodes=G.nodes()\n",
        "  lexical_dict={node:lexical_matrix(n) for node in nodes}\n",
        "  return [G,lexical_dict]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8X7dysfdFSjd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Second, we define some functions on lexical interests"
      ]
    },
    {
      "metadata": {
        "id": "df_bvR90FZ_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this function allows us to consider the level of lexical compromise of agents\n",
        "# matrix -> lexical matrix of the speaker\n",
        "# meaning -> selected column\n",
        "# speaker_interest -> if 0 the speaker selects the most ambiguous word; else, the speaker selects the least ambiguous word\n",
        "def select_word(matrix,meaning,speaker_interest):\n",
        "  # if the speaker does not known any word associated to the meaning\n",
        "  if np.sum(matrix[:,meaning])==0:\n",
        "    word=random.randint(0,len(matrix[:,meaning]))\n",
        "  else:\n",
        "    # sum of rows (number of meanings!)\n",
        "    sum_rows=matrix.sum(axis=1)\n",
        "    # select the words with the greatest ambiguity if speaker==0\n",
        "    if speaker_interest==0:\n",
        "      ambiguity=max(sum_rows)\n",
        "    else:\n",
        "      ambiguity=min(sum_rows)\n",
        "    # indices associated to ambiguity\n",
        "    indices_ambiguity=[index for index in range(len(sum_rows)) if sum_rows[index]==ambiguity]\n",
        "    # select only one word!\n",
        "    word=random.choice(indices_ambiguity)\n",
        "  return word\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lTxC-nWvR9k-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now, we define a simple speaker-hearer interaction\n",
        "# speaker, hearer -> agent's locations (nodes!)\n",
        "# lexical_dict -> dictionary of lexical metrices\n",
        "# speaker_interest -> if 0 the speaker selects the most ambiguous word; else, the speaker selects the least ambiguous word\n",
        "# meaning -> the topic of the conversation\n",
        "def interaction(speaker,hearer,lexical_dict,speaker_interest,meaning):\n",
        "  # lexical matrices\n",
        "  hearer_matrix=lexical_dict[hearer]\n",
        "  speaker_matrix=lexical_dict[speaker]\n",
        "  # the speaker selects one word according to its lexical compromise\n",
        "  r=random.randint(0,100)\n",
        "  if float(r)/101>speaker_interest:\n",
        "    word=select_word(lexical_dict[speaker],meaning,0)\n",
        "  else:\n",
        "    word=select_word(lexical_dict[speaker],meaning,1)\n",
        "  # now, simple naming game rules\n",
        "  # the hearer does not know the word (failure!)\n",
        "  if hearer_matrix[word][meaning]==0:\n",
        "    hearer_matrix[word][meaning]=1\n",
        "  lexical_dict[hearer]=hearer_matrix\n",
        "  # else (success!)\n",
        "  if hearer_matrix[word][meaning]==1:\n",
        "    n=len(speaker_matrix)\n",
        "    for i in range(n):\n",
        "      # all words are set to 0\n",
        "      hearer_matrix[i][meaning]=0\n",
        "      speaker_matrix[i][meaning]=0\n",
        "    # except one!\n",
        "    hearer_matrix[word][meaning]=1\n",
        "    speaker_matrix[word][meaning]=1\n",
        "  # update dict of lexical matrices\n",
        "  lexical_dict[hearer]=hearer_matrix\n",
        "  lexical_dict[speaker]=speaker_matrix\n",
        "  return lexical_dict\n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zmZwCyFv1OHt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Third, preparing the simulation"
      ]
    },
    {
      "metadata": {
        "id": "jbdG5y4GJ45E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# simulation of the agent-based model\n",
        "# time -> number of interactions\n",
        "# P -> population\n",
        "def simulation(time,P,speaker_interest,n):\n",
        "  # nodes \n",
        "  nodes=list(P[0].nodes())\n",
        "  # lexical_matrices\n",
        "  lexical_matrices=P[1]\n",
        "  # loop!\n",
        "  for i in tqdm(range(time)):\n",
        "    # topic of the conversation\n",
        "    meaning=random.choice(list(range(n)))\n",
        "    # speaker\n",
        "    speaker=random.choice(nodes)\n",
        "    # hearer\n",
        "    hearer=random.choice(list(P[0].neighbors(speaker)))\n",
        "    P[1]=interaction(speaker,hearer,P[1],speaker_interest,meaning)\n",
        "  \n",
        "  return P"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-XRAay1vpBxp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## measuring the effective vocabulary\n",
        "def effective_vocabulary(lexical_matrices,n): \n",
        "  a=0\n",
        "  for node in lexical_matrices.keys():\n",
        "    for i in range(n):\n",
        "      if sum(lexical_matrices[node][i,:])>0:\n",
        "        a+=1\n",
        "\n",
        "  return a/float(len(lexical_matrices.keys())*n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yUDBj-jbiP4_",
        "colab_type": "code",
        "outputId": "ca3693f4-02b3-4af6-ede0-52214838d0f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "n=20\n",
        "agents=20\n",
        "time=5000000\n",
        "speaker_interest=0\n",
        "P=population(agents,n)\n",
        "print(effective_vocabulary(P[1],n))\n",
        "print(effective_vocabulary(simulation(time,P,speaker_interest,n)[1],n))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1993/5000000 [00:00<04:10, 19926.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 4585199/5000000 [03:48<00:21, 19265.33it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "e3PCdMcrzh8m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "speaker_interest=1\n",
        "P=population(agents,n)\n",
        "print(effective_vocabulary(P[1],n))\n",
        "print(effective_vocabulary(simulation(time,P,speaker_interest,n)[1],n))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m8Z05a-q7Hnu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n=32\n",
        "agents=20\n",
        "time=5000000\n",
        "speaker_interest=[k/float(4) for k in range(5)]\n",
        "effective_vocabulary_dict={}\n",
        "for interest in speaker_interest:\n",
        "  P=population(agents,n)\n",
        "  effective_vocabulary_dict[interest]=effective_vocabulary(simulation(time,P,interest,n)[1],n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nKYJ9NL9Dzcn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "effective_vocabulary_dict"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}