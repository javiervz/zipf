{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zipf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/javiervz/zipf/blob/master/zipf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "k_FFUcAF53U9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**A decentralized route to the origins of scaling in human language**"
      ]
    },
    {
      "metadata": {
        "id": "gU_J7TyG6PSB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, we create a population "
      ]
    },
    {
      "metadata": {
        "id": "dae-aooi5uGy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "db5QZ_FR514F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# periodic grid graph of dim 2 and length L\n",
        "def grid(L):\n",
        "  G = nx.grid_graph([L,L],periodic=True)\n",
        "  return G"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YE8XTWjO1igo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# complete graph of L**2 nodes\n",
        "def complete(L):\n",
        "  G = nx.complete_graph(L**2)\n",
        "  return G"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sDBp6yHUB3-1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# matrix of ones and zeros (at random)\n",
        "def lexical_matrix(n):\n",
        "  M=np.array([1 if random.random()<0.5 else 0 for i in range(n**2)]).reshape(n,n)\n",
        "  return M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "obCJdNRz9APR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# a population is defined by a (i) graph; and (ii) a dict of numpy matrices (representing vocabularies)\n",
        "# L -> length of the grid \n",
        "# n -> number of words (rows of the lexical matrices)\n",
        "# n -> number of meanings (columns of lexical matrices) (that is, only squared matrices)\n",
        "def population(L,n):\n",
        "  # grid (or complete) graph\n",
        "  G=complete(L)\n",
        "  nodes=G.nodes()\n",
        "  lexical_dict={node:lexical_matrix(n) for node in nodes}\n",
        "  return [G,lexical_dict]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8X7dysfdFSjd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Second, we define some functions on lexical interests"
      ]
    },
    {
      "metadata": {
        "id": "df_bvR90FZ_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this function allows us to consider the level of lexical compromise of agents\n",
        "# matrix -> lexical matrix of the speaker\n",
        "# meaning -> selected column\n",
        "# speaker_interest -> if 0 the speaker selects the most ambiguous word; else, the speaker selects the least ambiguous word\n",
        "def select_word(matrix,meaning,speaker_interest):\n",
        "  # if the speaker does not known any word associated to the meaning\n",
        "  if np.sum(matrix[:,meaning])==0:\n",
        "    word=random.randint(0,len(matrix[:,meaning])-1)\n",
        "  else:\n",
        "    # sum of rows (number of meanings!) associated to the meaning (using the hadamard product)\n",
        "    sum_rows=matrix.sum(axis=1)*matrix[:,meaning]\n",
        "    # select the words with the greatest ambiguity if speaker==0\n",
        "    if speaker_interest==0:\n",
        "      ambiguity=max(sum_rows)\n",
        "    else:\n",
        "      ambiguity=max(min(sum_rows),0)\n",
        "    # indices associated to ambiguity\n",
        "    indices_ambiguity=[index for index in range(len(sum_rows)) if sum_rows[index]==ambiguity]\n",
        "    # select only one word!\n",
        "    word=random.choice(indices_ambiguity)\n",
        "  return word\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lTxC-nWvR9k-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now, we propose a simple speaker-hearer interaction\n",
        "# speaker, hearer -> agent's locations (nodes!)\n",
        "# lexical_dict -> dictionary of lexical metrices\n",
        "# speaker_interest -> if 0 the speaker selects the most ambiguous word; else, the speaker selects the least ambiguous word\n",
        "# meaning -> the topic of the conversation\n",
        "def interaction(speaker,hearer,lexical_dict,speaker_interest,meaning):\n",
        "  # lexical matrices\n",
        "  hearer_matrix=lexical_dict[hearer]\n",
        "  speaker_matrix=lexical_dict[speaker]\n",
        "  # the speaker selects one word according to its lexical compromise\n",
        "  r=random.randint(0,101)\n",
        "  if float(r)/100>speaker_interest:\n",
        "    word=select_word(lexical_dict[speaker],meaning,0)\n",
        "  else:\n",
        "    word=select_word(lexical_dict[speaker],meaning,1)\n",
        "  # now, simple naming game rules\n",
        "  # the hearer does not know the word (failure!)\n",
        "  if hearer_matrix[word][meaning]==0:\n",
        "    hearer_matrix[word][meaning]=1\n",
        "  #lexical_dict[hearer]=hearer_matrix\n",
        "  # else (success!)\n",
        "  else:\n",
        "    n=len(speaker_matrix)\n",
        "    for i in range(n):\n",
        "      # all words are set to 0\n",
        "      hearer_matrix[i][meaning]=0\n",
        "      speaker_matrix[i][meaning]=0\n",
        "    # except one!\n",
        "    hearer_matrix[word][meaning]=1\n",
        "    speaker_matrix[word][meaning]=1\n",
        "  # update dict of lexical matrices\n",
        "  lexical_dict[hearer]=hearer_matrix\n",
        "  lexical_dict[speaker]=speaker_matrix\n",
        "  return lexical_dict\n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zmZwCyFv1OHt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Third, preparing the simulation"
      ]
    },
    {
      "metadata": {
        "id": "jbdG5y4GJ45E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# simulation of the agent-based model\n",
        "# time -> number of interactions\n",
        "# P -> population\n",
        "def simulation(time,P,speaker_interest,n):\n",
        "  # nodes \n",
        "  nodes=list(P[0].nodes())\n",
        "  # lexical_matrices\n",
        "  lexical_matrices=P[1]\n",
        "  # loop!\n",
        "  for i in tqdm(range(time)):\n",
        "    # topic of the conversation\n",
        "    meaning=random.randint(0,n-1)\n",
        "    # speaker\n",
        "    speaker=random.choice(nodes)\n",
        "    # hearer\n",
        "    hearer=random.choice(list(P[0].neighbors(speaker)))\n",
        "    P[1]=interaction(speaker,hearer,P[1],speaker_interest,meaning)\n",
        "  \n",
        "  return P"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-XRAay1vpBxp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## measuring the effective vocabulary\n",
        "def effective_vocabulary(lexical_matrices,n): \n",
        "  a=0\n",
        "  for node in lexical_matrices.keys():\n",
        "    for i in range(n):\n",
        "      if sum(lexical_matrices[node][i,:])>0:\n",
        "        a+=1\n",
        "\n",
        "  return a/float(len(lexical_matrices.keys())*n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rCrXDZ4preiN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n=64\n",
        "agents=10\n",
        "time=10000000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m8Z05a-q7Hnu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "speaker_interest=[k/float(10) for k in range(11)]\n",
        "effective_vocabulary_dict={}\n",
        "for interest in speaker_interest:\n",
        "  P=population(agents,n)\n",
        "  effective_vocabulary_dict[interest]=effective_vocabulary(simulation(time,P,interest,n)[1],n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nKYJ9NL9Dzcn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "effective_vocabulary_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IntDSpytAGw6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0AWom1ZL_OTS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(dpi=800)\n",
        "X=list(effective_vocabulary_dict.keys())\n",
        "Y=list(effective_vocabulary_dict.values())\n",
        "\n",
        "ax.plot(X,Y, color='r',marker='*',markersize=6,fillstyle='none',markeredgewidth=0.5,clip_on=True,linewidth=0.5)\n",
        "\n",
        "plt.grid(False)\n",
        "#plt.legend(loc='best')\n",
        "plt.ylabel(r'effective vocabulary $V(\\wp)$',fontsize=15)\n",
        "plt.xlabel(r'speaker interest $\\wp$',fontsize=15)\n",
        "plt.rcParams.update({'font.size': 10})\n",
        "plt.savefig('/content/drive/My Drive/zipf/effective_vocabulary.pdf', format='pdf', transparent=True, bbox_inches='tight',dpi=800)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "itwNC6oReNj3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#initial_conditions=[(time,population(agents,64),k/float(4),64) for k in range(5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KYOGxynXepop",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from itertools import starmap                                                     \n",
        "#map_simulation=list(starmap(simulation, initial_conditions))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}