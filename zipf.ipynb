{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zipf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/javiervz/zipf/blob/master/zipf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "k_FFUcAF53U9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**A decentralized route to the origins of scaling in human language**"
      ]
    },
    {
      "metadata": {
        "id": "gU_J7TyG6PSB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, we create a population "
      ]
    },
    {
      "metadata": {
        "id": "dae-aooi5uGy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "db5QZ_FR514F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# periodic grid graph of dim 2 and length L\n",
        "def grid(L):\n",
        "  G = nx.grid_graph([L,L],periodic=True)\n",
        "  return G"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YE8XTWjO1igo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# complete graph of L**2 nodes\n",
        "def complete(L):\n",
        "  G = nx.complete_graph(L**2)\n",
        "  return G"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sDBp6yHUB3-1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# matrix of ones and zeros (at random)\n",
        "def lexical_matrix(n):\n",
        "  M=np.array([1 if random.random()<0.5 else 0 for i in range(n**2)]).reshape(n,n)\n",
        "  return M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "obCJdNRz9APR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# a population is defined by a (i) graph; and (ii) a dict of numpy matrices (representing vocabularies)\n",
        "# L -> length of the grid \n",
        "# n -> number of words (rows of the lexical matrices)\n",
        "# n -> number of meanings (columns of lexical matrices) (that is, only squared matrices)\n",
        "def population(L,n):\n",
        "  # grid (or complete) graph\n",
        "  G=grid(L)\n",
        "  nodes=G.nodes()\n",
        "  lexical_dict={node:lexical_matrix(n) for node in nodes}\n",
        "  return [G,lexical_dict]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8X7dysfdFSjd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Second, we define some functions on lexical interests"
      ]
    },
    {
      "metadata": {
        "id": "df_bvR90FZ_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this function allows us to consider the level of lexical compromise of agents\n",
        "# matrix -> lexical matrix of the speaker\n",
        "# meaning -> selected column\n",
        "# speaker_interest -> if 0 the speaker selects the most ambiguous word; else, the speaker selects the least ambiguous word\n",
        "def select_word(matrix,meaning,speaker_interest):\n",
        "  # if the speaker does not known any word associated to the meaning\n",
        "  if np.sum(matrix[:,meaning])==0:\n",
        "    word=random.randint(0,len(matrix[:,meaning])-1)\n",
        "  else:\n",
        "    # sum of rows (number of meanings!) associated to the meaning (using the hadamard product)\n",
        "    sum_rows=matrix.sum(axis=1)*matrix[:,meaning]\n",
        "    # select the words with the greatest ambiguity if speaker==0\n",
        "    if speaker_interest==0:\n",
        "      ambiguity=max(sum_rows)\n",
        "    else:\n",
        "      ambiguity=max(min(sum_rows),0)\n",
        "    # indices associated to ambiguity\n",
        "    indices_ambiguity=[index for index in range(len(sum_rows)) if sum_rows[index]==ambiguity]\n",
        "    # select only one word!\n",
        "    word=random.choice(indices_ambiguity)\n",
        "  return word\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lTxC-nWvR9k-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now, we propose a simple speaker-hearer interaction\n",
        "# speaker, hearer -> agent's locations (nodes!)\n",
        "# lexical_dict -> dictionary of lexical metrices\n",
        "# speaker_interest -> if 0 the speaker selects the most ambiguous word; else, the speaker selects the least ambiguous word\n",
        "# meaning -> the topic of the conversation\n",
        "def interaction(speaker,hearer,lexical_dict,speaker_interest,meaning):\n",
        "  # lexical matrices\n",
        "  hearer_matrix=lexical_dict[hearer]\n",
        "  speaker_matrix=lexical_dict[speaker]\n",
        "  # the speaker selects one word according to its lexical compromise\n",
        "  r=random.randint(0,100)\n",
        "  if float(r)/101>speaker_interest:\n",
        "    word=select_word(lexical_dict[speaker],meaning,0)\n",
        "  else:\n",
        "    word=select_word(lexical_dict[speaker],meaning,1)\n",
        "  # now, simple naming game rules\n",
        "  # the hearer does not know the word (failure!)\n",
        "  if hearer_matrix[word][meaning]==0:\n",
        "    hearer_matrix[word][meaning]=1\n",
        "  #lexical_dict[hearer]=hearer_matrix\n",
        "  # else (success!)\n",
        "  else:\n",
        "    n=len(speaker_matrix)\n",
        "    for i in range(n):\n",
        "      # all words are set to 0\n",
        "      hearer_matrix[i][meaning]=0\n",
        "      speaker_matrix[i][meaning]=0\n",
        "    # except one!\n",
        "    hearer_matrix[word][meaning]=1\n",
        "    speaker_matrix[word][meaning]=1\n",
        "  # update dict of lexical matrices\n",
        "  lexical_dict[hearer]=hearer_matrix\n",
        "  lexical_dict[speaker]=speaker_matrix\n",
        "  return lexical_dict\n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zmZwCyFv1OHt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Third, preparing the simulation"
      ]
    },
    {
      "metadata": {
        "id": "jbdG5y4GJ45E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# simulation of the agent-based model\n",
        "# time -> number of interactions\n",
        "# P -> population\n",
        "def simulation(time,P,speaker_interest,n):\n",
        "  # nodes \n",
        "  nodes=list(P[0].nodes())\n",
        "  # lexical_matrices\n",
        "  lexical_matrices=P[1]\n",
        "  # loop!\n",
        "  for i in tqdm(range(time)):\n",
        "    # topic of the conversation\n",
        "    meaning=random.randint(0,n-1)\n",
        "    # speaker\n",
        "    speaker=random.choice(nodes)\n",
        "    # hearer\n",
        "    hearer=random.choice(list(P[0].neighbors(speaker)))\n",
        "    P[1]=interaction(speaker,hearer,P[1],speaker_interest,meaning)\n",
        "  \n",
        "  return P"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-XRAay1vpBxp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## measuring the effective vocabulary\n",
        "def effective_vocabulary(lexical_matrices,n): \n",
        "  a=0\n",
        "  for node in lexical_matrices.keys():\n",
        "    for i in range(n):\n",
        "      if sum(lexical_matrices[node][i,:])>0:\n",
        "        a+=1\n",
        "\n",
        "  return a/float(len(lexical_matrices.keys())*n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rCrXDZ4preiN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n=64\n",
        "agents=64\n",
        "time=10000000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yUDBj-jbiP4_",
        "colab_type": "code",
        "outputId": "2cb0b3bd-e210-4edd-8f8b-4afa7cea7dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "speaker_interest=0\n",
        "P=population(agents,n)\n",
        "print(effective_vocabulary(P[1],n))\n",
        "print(effective_vocabulary(simulation(time,P,speaker_interest,n)[1],n))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1441/10000000 [00:00<11:34, 14404.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000000/10000000 [13:22<00:00, 12456.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.07503890991210938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e3PCdMcrzh8m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "05a8fa8f-9789-4802-8fa6-824225477d3d"
      },
      "cell_type": "code",
      "source": [
        "speaker_interest=1\n",
        "P=population(agents,n)\n",
        "print(effective_vocabulary(P[1],n))\n",
        "print(effective_vocabulary(simulation(time,P,speaker_interest,n)[1],n))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1343/10000000 [00:00<12:24, 13428.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000000/10000000 [09:03<00:00, 18415.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9956817626953125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m8Z05a-q7Hnu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "d32b4861-2b23-42c2-9077-22247864d793"
      },
      "cell_type": "code",
      "source": [
        "speaker_interest=[k/float(10) for k in range(11)]\n",
        "effective_vocabulary_dict={}\n",
        "for interest in speaker_interest:\n",
        "  P=population(agents,n)\n",
        "  effective_vocabulary_dict[interest]=effective_vocabulary(simulation(time,P,interest,n)[1],n)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000000/10000000 [13:15<00:00, 12568.98it/s]\n",
            "100%|██████████| 10000000/10000000 [12:33<00:00, 13271.68it/s]\n",
            "100%|██████████| 10000000/10000000 [12:12<00:00, 13657.92it/s]\n",
            "100%|██████████| 10000000/10000000 [11:38<00:00, 14313.31it/s]\n",
            "100%|██████████| 10000000/10000000 [11:05<00:00, 15034.46it/s]\n",
            "100%|██████████| 10000000/10000000 [10:34<00:00, 15760.89it/s]\n",
            "100%|██████████| 10000000/10000000 [10:03<00:00, 16576.25it/s]\n",
            "100%|██████████| 10000000/10000000 [09:30<00:00, 17521.55it/s]\n",
            "100%|██████████| 10000000/10000000 [09:19<00:00, 17874.00it/s]\n",
            "100%|██████████| 10000000/10000000 [09:07<00:00, 18279.98it/s]\n",
            "100%|██████████| 10000000/10000000 [09:14<00:00, 18033.37it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nKYJ9NL9Dzcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "a8d34857-bde7-433b-f995-d15df718b706"
      },
      "cell_type": "code",
      "source": [
        "effective_vocabulary_dict"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.0: 0.07289505004882812,\n",
              " 0.1: 0.14385604858398438,\n",
              " 0.2: 0.22898101806640625,\n",
              " 0.3: 0.3368797302246094,\n",
              " 0.4: 0.4668006896972656,\n",
              " 0.5: 0.61724853515625,\n",
              " 0.6: 0.78997802734375,\n",
              " 0.7: 0.9363441467285156,\n",
              " 0.8: 0.9871711730957031,\n",
              " 0.9: 0.9944419860839844,\n",
              " 1.0: 0.9954376220703125}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "itwNC6oReNj3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "initial_conditions=[(time,population(agents,64),k/float(4),64) for k in range(5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KYOGxynXepop",
        "colab_type": "code",
        "outputId": "69139c15-9c22-450a-8258-ea7d178f555b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        }
      },
      "cell_type": "code",
      "source": [
        "from itertools import starmap                                                     \n",
        "map_simulation=list(starmap(simulation, initial_conditions))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 44%|████▎     | 4366644/10000000 [05:29<07:40, 12230.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f4343f648166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmap_simulation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_conditions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-ca2b87b67754>\u001b[0m in \u001b[0;36msimulation\u001b[0;34m(time, P, speaker_interest, n)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# hearer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mhearer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeaker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minteraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeaker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhearer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspeaker_interest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmeaning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-6eb75a165d1b>\u001b[0m in \u001b[0;36minteraction\u001b[0;34m(speaker, hearer, lexical_dict, speaker_interest, meaning)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mspeaker_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlexical_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspeaker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# the speaker selects one word according to its lexical compromise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mspeaker_interest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselect_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexical_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspeaker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmeaning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/random.py\u001b[0m in \u001b[0;36mrandint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \"\"\"\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     def _randbelow(self, n, int=int, maxsize=1<<BPF, type=type,\n",
            "\u001b[0;32m/usr/lib/python3.6/random.py\u001b[0m in \u001b[0;36mrandrange\u001b[0;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mistop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mistart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mistart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empty range for randrange() (%d,%d, %d)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mistart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}